{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 5: Multi-Collection RAG with Metadata Filtering\n",
    "Pattern: Enterprise RAG with Collections\n",
    "\n",
    "**Features:**\n",
    "- Collection routing (Technical Docs, FAQs, Memos)\n",
    "- Metadata-based filtering\n",
    "- Collection-specific prompts\n",
    "- Smart routing based on query type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Configuration\n",
    "MULTI_COLLECTION_BUCKET = f\"multi-collection-demo-{int(time.time())}\"\n",
    "EMBEDDING_MODEL = \"amazon.titan-embed-text-v1\"\n",
    "GENERATION_MODEL = \"amazon.nova-pro-v1:0\""
   ]
  }
 ],
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket\n",
    "s3.create_bucket(Bucket=MULTI_COLLECTION_BUCKET)\n",
    "print(f\"Created multi-collection bucket: {MULTI_COLLECTION_BUCKET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-collection document database\n",
    "collections = {\n",
    "    \"technical_docs\": [\n",
    "        {\n",
    "            \"id\": \"tech_001\",\n",
    "            \"title\": \"Lambda Architecture Guide\",\n",
    "            \"content\": \"AWS Lambda follows serverless architecture patterns. Functions are stateless, event-driven, and automatically scaled. Best practices include proper error handling, monitoring, and resource optimization.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"technical_docs\",\n",
    "                \"category\": \"architecture\",\n",
    "                \"author\": \"AWS Solutions Team\",\n",
    "                \"created_date\": \"2024-01-15\",\n",
    "                \"tags\": [\"serverless\", \"architecture\", \"best-practices\"],\n",
    "                \"difficulty\": \"intermediate\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"tech_002\",\n",
    "            \"title\": \"Lambda Performance Optimization\",\n",
    "            \"content\": \"Optimize Lambda performance through memory allocation, cold start reduction, connection pooling, and efficient code practices. Monitor with CloudWatch and X-Ray for bottleneck identification.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"technical_docs\",\n",
    "                \"category\": \"performance\",\n",
    "                \"author\": \"Performance Team\",\n",
    "                \"created_date\": \"2024-02-01\",\n",
    "                \"tags\": [\"performance\", \"optimization\", \"monitoring\"],\n",
    "                \"difficulty\": \"advanced\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"faqs\": [\n",
    "        {\n",
    "            \"id\": \"faq_001\",\n",
    "            \"title\": \"Lambda Pricing FAQ\",\n",
    "            \"content\": \"Q: How is Lambda priced? A: Lambda charges $0.20 per 1M requests and $0.0000166667 per GB-second. Free tier includes 1M requests monthly. Q: Are there additional charges? A: Data transfer and other AWS service usage may incur additional costs.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"faqs\",\n",
    "                \"category\": \"pricing\",\n",
    "                \"author\": \"Support Team\",\n",
    "                \"created_date\": \"2024-01-10\",\n",
    "                \"tags\": [\"pricing\", \"billing\", \"costs\"],\n",
    "                \"difficulty\": \"beginner\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"faq_002\",\n",
    "            \"title\": \"Lambda Limits FAQ\",\n",
    "            \"content\": \"Q: What are Lambda limits? A: 15-minute max execution, 10GB memory max, 512MB /tmp storage. Q: Can limits be increased? A: Some limits can be increased via support tickets, others are hard limits.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"faqs\",\n",
    "                \"category\": \"limits\",\n",
    "                \"author\": \"Support Team\",\n",
    "                \"created_date\": \"2024-01-20\",\n",
    "                \"tags\": [\"limits\", \"quotas\", \"constraints\"],\n",
    "                \"difficulty\": \"beginner\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"memos\": [\n",
    "        {\n",
    "            \"id\": \"memo_001\",\n",
    "            \"title\": \"Lambda Security Update\",\n",
    "            \"content\": \"MEMO: New security guidelines for Lambda functions. All functions must use IAM roles with least privilege. Secrets must be stored in AWS Secrets Manager. Enable encryption for sensitive data.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"memos\",\n",
    "                \"category\": \"security\",\n",
    "                \"author\": \"Security Team\",\n",
    "                \"created_date\": \"2024-02-15\",\n",
    "                \"tags\": [\"security\", \"compliance\", \"policy\"],\n",
    "                \"difficulty\": \"intermediate\",\n",
    "                \"priority\": \"high\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"memo_002\",\n",
    "            \"title\": \"Lambda Cost Optimization Initiative\",\n",
    "            \"content\": \"MEMO: Company-wide initiative to optimize Lambda costs. Review memory allocation, implement ARM processors where possible, and monitor usage patterns. Target 20% cost reduction by Q2.\",\n",
    "            \"metadata\": {\n",
    "                \"collection\": \"memos\",\n",
    "                \"category\": \"cost-optimization\",\n",
    "                \"author\": \"Finance Team\",\n",
    "                \"created_date\": \"2024-02-20\",\n",
    "                \"tags\": [\"cost\", \"optimization\", \"initiative\"],\n",
    "                \"difficulty\": \"intermediate\",\n",
    "                \"priority\": \"medium\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Loaded collections:\")\n",
    "for collection_name, docs in collections.items():\n",
    "    print(f\"  {collection_name}: {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Get embedding using Titan model\"\"\"\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=EMBEDDING_MODEL,\n",
    "        body=json.dumps({\"inputText\": text})\n",
    "    )\n",
    "    return json.loads(response['body'].read())['embedding']\n",
    "\n",
    "def create_collection_indexes():\n",
    "    \"\"\"Create vector indexes for each collection\"\"\"\n",
    "    collection_indexes = {}\n",
    "    \n",
    "    print(\"Creating collection indexes...\")\n",
    "    \n",
    "    for collection_name, documents in collections.items():\n",
    "        print(f\"\\nProcessing {collection_name}:\")\n",
    "        collection_indexes[collection_name] = {}\n",
    "        \n",
    "        for doc in documents:\n",
    "            # Create embedding\n",
    "            embedding = get_embedding(doc[\"content\"])\n",
    "            \n",
    "            collection_indexes[collection_name][doc[\"id\"]] = {\n",
    "                \"embedding\": embedding,\n",
    "                \"document\": doc\n",
    "            }\n",
    "            \n",
    "            print(f\"  Indexed {doc['id']}\")\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    return collection_indexes\n",
    "\n",
    "# Create indexes\n",
    "collection_indexes = create_collection_indexes()\n",
    "print(\"\\nAll collection indexes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query_to_collections(query: str) -> List[str]:\n",
    "    \"\"\"Smart routing: determine which collections to search based on query\"\"\"\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Collection routing rules\n",
    "    routing_rules = {\n",
    "        \"technical_docs\": [\"architecture\", \"implementation\", \"design\", \"technical\", \"how to\", \"guide\", \"tutorial\"],\n",
    "        \"faqs\": [\"what is\", \"how much\", \"pricing\", \"cost\", \"limit\", \"faq\", \"question\", \"?\"],\n",
    "        \"memos\": [\"policy\", \"announcement\", \"memo\", \"update\", \"initiative\", \"guideline\", \"security\"]\n",
    "    }\n",
    "    \n",
    "    selected_collections = []\n",
    "    \n",
    "    # Check each collection for matching keywords\n",
    "    for collection, keywords in routing_rules.items():\n",
    "        if any(keyword in query_lower for keyword in keywords):\n",
    "            selected_collections.append(collection)\n",
    "    \n",
    "    # If no specific routing, search all collections\n",
    "    if not selected_collections:\n",
    "        selected_collections = list(collections.keys())\n",
    "    \n",
    "    return selected_collections\n",
    "\n",
    "def filter_by_metadata(documents: List[Dict], filters: Dict) -> List[Dict]:\n",
    "    \"\"\"Filter documents based on metadata criteria\"\"\"\n",
    "    \n",
    "    filtered_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        metadata = doc[\"document\"][\"metadata\"]\n",
    "        include_doc = True\n",
    "        \n",
    "        for filter_key, filter_value in filters.items():\n",
    "            if filter_key in metadata:\n",
    "                if isinstance(filter_value, list):\n",
    "                    # Check if any filter value matches\n",
    "                    if isinstance(metadata[filter_key], list):\n",
    "                        # Both are lists - check intersection\n",
    "                        if not set(filter_value) & set(metadata[filter_key]):\n",
    "                            include_doc = False\n",
    "                            break\n",
    "                    else:\n",
    "                        # Filter is list, metadata is single value\n",
    "                        if metadata[filter_key] not in filter_value:\n",
    "                            include_doc = False\n",
    "                            break\n",
    "                else:\n",
    "                    # Simple equality check\n",
    "                    if metadata[filter_key] != filter_value:\n",
    "                        include_doc = False\n",
    "                        break\n",
    "        \n",
    "        if include_doc:\n",
    "            filtered_docs.append(doc)\n",
    "    \n",
    "    return filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: List[float], b: List[float]) -> float:\n",
    "    \"\"\"Calculate cosine similarity\"\"\"\n",
    "    a_np = np.array(a)\n",
    "    b_np = np.array(b)\n",
    "    return np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np))\n",
    "\n",
    "def search_collections(query: str, \n",
    "                      target_collections: List[str], \n",
    "                      metadata_filters: Optional[Dict] = None,\n",
    "                      top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Search across specified collections with metadata filtering\"\"\"\n",
    "    \n",
    "    query_embedding = get_embedding(query)\n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"Searching collections: {target_collections}\")\n",
    "    if metadata_filters:\n",
    "        print(f\"Metadata filters: {metadata_filters}\")\n",
    "    \n",
    "    # Search each target collection\n",
    "    for collection_name in target_collections:\n",
    "        if collection_name not in collection_indexes:\n",
    "            continue\n",
    "            \n",
    "        collection_results = []\n",
    "        \n",
    "        # Calculate similarities for this collection\n",
    "        for doc_id, data in collection_indexes[collection_name].items():\n",
    "            similarity = cosine_similarity(query_embedding, data[\"embedding\"])\n",
    "            \n",
    "            collection_results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"document\": data[\"document\"],\n",
    "                \"similarity\": similarity,\n",
    "                \"collection\": collection_name\n",
    "            })\n",
    "        \n",
    "        # Apply metadata filters if specified\n",
    "        if metadata_filters:\n",
    "            collection_results = filter_by_metadata(collection_results, metadata_filters)\n",
    "        \n",
    "        all_results.extend(collection_results)\n",
    "        print(f\"  {collection_name}: {len(collection_results)} results\")\n",
    "    \n",
    "    # Sort all results by similarity and return top_k\n",
    "    all_results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    return all_results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_specific_prompt(collection_name: str) -> str:\n",
    "    \"\"\"Get collection-specific prompt templates\"\"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"technical_docs\": \"Based on the following technical documentation, provide a detailed and accurate technical answer:\",\n",
    "        \"faqs\": \"Based on the following FAQ information, provide a clear and concise answer:\",\n",
    "        \"memos\": \"Based on the following company memos and policies, provide guidance that aligns with company directives:\"\n",
    "    }\n",
    "    \n",
    "    return prompts.get(collection_name, \"Based on the following information, provide an accurate answer:\")\n",
    "\n",
    "def generate_multi_collection_answer(query: str, search_results: List[Dict]) -> str:\n",
    "    \"\"\"Generate answer using collection-specific prompts\"\"\"\n",
    "    \n",
    "    # Group results by collection\n",
    "    collection_groups = {}\n",
    "    for result in search_results:\n",
    "        collection = result[\"collection\"]\n",
    "        if collection not in collection_groups:\n",
    "            collection_groups[collection] = []\n",
    "        collection_groups[collection].append(result)\n",
    "    \n",
    "    # Build context with collection-specific formatting\n",
    "    context_parts = []\n",
    "    \n",
    "    for collection, results in collection_groups.items():\n",
    "        collection_prompt = get_collection_specific_prompt(collection)\n",
    "        context_parts.append(f\"\\n=== {collection.upper().replace('_', ' ')} ===\")\n",
    "        \n",
    "        for result in results:\n",
    "            doc = result[\"document\"]\n",
    "            metadata = doc[\"metadata\"]\n",
    "            context_parts.append(f\"Title: {doc['title']}\")\n",
    "            context_parts.append(f\"Content: {doc['content']}\")\n",
    "            context_parts.append(f\"Author: {metadata['author']} | Date: {metadata['created_date']}\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Determine primary collection for prompt selection\n",
    "    primary_collection = max(collection_groups.keys(), key=lambda x: len(collection_groups[x]))\n",
    "    primary_prompt = get_collection_specific_prompt(primary_collection)\n",
    "    \n",
    "    prompt = f\"\"\"{primary_prompt}\n",
    "\n",
    "Context from multiple collections:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer (consider information from all relevant collections):\"\"\"\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=GENERATION_MODEL,\n",
    "        body=json.dumps({\n",
    "            \"messages\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": prompt}]\n",
    "            }],\n",
    "            \"inferenceConfig\": {\n",
    "                \"maxTokens\": 400,\n",
    "                \"temperature\": 0.1\n",
    "            }\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['body'].read())\n",
    "    return result['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_collection_rag(query: str, metadata_filters: Optional[Dict] = None) -> Dict:\n",
    "    \"\"\"Complete multi-collection RAG pipeline\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MULTI-COLLECTION RAG QUERY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    # Step 1: Route query to appropriate collections\n",
    "    target_collections = route_query_to_collections(query)\n",
    "    print(f\"Routed to collections: {target_collections}\\n\")\n",
    "    \n",
    "    # Step 2: Search with metadata filtering\n",
    "    search_results = search_collections(query, target_collections, metadata_filters, top_k=3)\n",
    "    \n",
    "    print(f\"\\nSearch results:\")\n",
    "    for i, result in enumerate(search_results, 1):\n",
    "        doc = result[\"document\"]\n",
    "        metadata = doc[\"metadata\"]\n",
    "        print(f\"  {i}. [{result['collection']}] {doc['title']}\")\n",
    "        print(f\"     Similarity: {result['similarity']:.3f} | Author: {metadata['author']}\")\n",
    "    \n",
    "    # Step 3: Generate collection-aware answer\n",
    "    answer = generate_multi_collection_answer(query, search_results)\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"target_collections\": target_collections,\n",
    "        \"metadata_filters\": metadata_filters,\n",
    "        \"results_count\": len(search_results),\n",
    "        \"collections_used\": list(set(r[\"collection\"] for r in search_results)),\n",
    "        \"answer\": answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-collection RAG with different query types\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"query\": \"What are Lambda pricing costs?\",\n",
    "        \"filters\": None,\n",
    "        \"description\": \"FAQ-style query (should route to FAQs)\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How to implement Lambda architecture?\",\n",
    "        \"filters\": None,\n",
    "        \"description\": \"Technical query (should route to technical docs)\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Lambda security policy updates\",\n",
    "        \"filters\": None,\n",
    "        \"description\": \"Policy query (should route to memos)\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Lambda optimization\",\n",
    "        \"filters\": {\"category\": [\"performance\", \"cost-optimization\"]},\n",
    "        \"description\": \"Filtered search (performance or cost optimization)\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Recent Lambda updates\",\n",
    "        \"filters\": {\"created_date\": \"2024-02-15\"},\n",
    "        \"description\": \"Date-filtered search\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\nScenario: {scenario['description']}\")\n",
    "    result = multi_collection_rag(scenario[\"query\"], scenario[\"filters\"])\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate metadata filtering capabilities\n",
    "print(\"METADATA FILTERING EXAMPLES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Example 1: Filter by difficulty level\n",
    "print(\"\\n1. Filter by difficulty level (beginner):\")\n",
    "beginner_results = search_collections(\n",
    "    \"Lambda information\", \n",
    "    [\"faqs\", \"technical_docs\"], \n",
    "    {\"difficulty\": \"beginner\"},\n",
    "    top_k=5\n",
    ")\n",
    "for result in beginner_results:\n",
    "    doc = result[\"document\"]\n",
    "    print(f\"  - {doc['title']} (difficulty: {doc['metadata']['difficulty']})\")\n",
    "\n",
    "# Example 2: Filter by tags\n",
    "print(\"\\n2. Filter by tags (security):\")\n",
    "security_results = search_collections(\n",
    "    \"Lambda security\", \n",
    "    list(collections.keys()), \n",
    "    {\"tags\": [\"security\"]},\n",
    "    top_k=5\n",
    ")\n",
    "for result in security_results:\n",
    "    doc = result[\"document\"]\n",
    "    print(f\"  - {doc['title']} (tags: {doc['metadata']['tags']})\")\n",
    "\n",
    "# Example 3: Filter by author\n",
    "print(\"\\n3. Filter by author (Security Team):\")\n",
    "security_team_results = search_collections(\n",
    "    \"Lambda guidelines\", \n",
    "    list(collections.keys()), \n",
    "    {\"author\": \"Security Team\"},\n",
    "    top_k=5\n",
    ")\n",
    "for result in security_team_results:\n",
    "    doc = result[\"document\"]\n",
    "    print(f\"  - {doc['title']} (author: {doc['metadata']['author']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Collection RAG Benefits\n",
    "\n",
    "### Enterprise-Grade Organization:\n",
    "✅ **Collection Routing**: Automatically routes queries to relevant document types  \n",
    "✅ **Metadata Filtering**: Filter by author, date, category, tags, difficulty  \n",
    "✅ **Collection-Specific Prompts**: Tailored responses based on document type  \n",
    "✅ **Scalable Architecture**: Easy to add new collections and metadata fields  \n",
    "\n",
    "### Collection Types:\n",
    "- **Technical Docs**: Architecture guides, implementation details, tutorials\n",
    "- **FAQs**: Common questions, pricing info, limits and quotas\n",
    "- **Memos**: Company policies, announcements, internal guidelines\n",
    "\n",
    "### Smart Routing Rules:\n",
    "- **Technical queries** → Technical Docs collection\n",
    "- **Question-style queries** → FAQs collection  \n",
    "- **Policy/announcement queries** → Memos collection\n",
    "- **Ambiguous queries** → Search all collections\n",
    "\n",
    "### Metadata Filtering Examples:\n",
    "- **By difficulty**: `{\"difficulty\": \"beginner\"}`\n",
    "- **By tags**: `{\"tags\": [\"security\", \"performance\"]}`\n",
    "- **By author**: `{\"author\": \"Security Team\"}`\n",
    "- **By date**: `{\"created_date\": \"2024-02-15\"}`\n",
    "- **Multiple filters**: `{\"category\": \"security\", \"priority\": \"high\"}`\n",
    "\n",
    "### When to Use Multi-Collection RAG:\n",
    "- **Enterprise knowledge bases** with diverse document types\n",
    "- **Large organizations** with multiple content sources\n",
    "- **Compliance requirements** needing document traceability\n",
    "- **Role-based access** to different information types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance summary\n",
    "print(\"MULTI-COLLECTION RAG PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "collection_usage = {}\n",
    "for result in results:\n",
    "    for collection in result[\"collections_used\"]:\n",
    "        collection_usage[collection] = collection_usage.get(collection, 0) + 1\n",
    "\n",
    "print(f\"Collection usage across {len(results)} queries:\")\n",
    "for collection, count in collection_usage.items():\n",
    "    print(f\"  {collection}: {count} times\")\n",
    "\n",
    "print(f\"\\nRouting accuracy:\")\n",
    "for i, result in enumerate(results):\n",
    "    scenario = test_scenarios[i]\n",
    "    print(f\"  Query {i+1}: {len(result['target_collections'])} collections targeted\")\n",
    "\n",
    "print(f\"\\nDemo complete! Multi-collection bucket: {MULTI_COLLECTION_BUCKET}\")\n",
    "print(\"Multi-collection RAG enables enterprise-grade knowledge management with smart routing and metadata filtering.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
