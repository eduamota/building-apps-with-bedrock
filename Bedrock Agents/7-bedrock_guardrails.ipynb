{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Guardrails\n",
    "Explore content filtering, PII redaction, topic blocking, and word filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "REGION = 'us-east-1'\n",
    "bedrock = boto3.client('bedrock', region_name=REGION)\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=REGION)\n",
    "\n",
    "print(f\"Region: {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Basic Guardrail with Content Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name='content-filter-guardrail',\n",
    "    description='Filter harmful content',\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {'type': 'HATE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'VIOLENCE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'SEXUAL', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'MISCONDUCT', 'inputStrength': 'MEDIUM', 'outputStrength': 'MEDIUM'}\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Your input was blocked due to content policy.',\n",
    "    blockedOutputsMessaging='The response was blocked due to content policy.'\n",
    ")\n",
    "\n",
    "GUARDRAIL_ID = response['guardrailId']\n",
    "GUARDRAIL_VERSION = response['version']\n",
    "\n",
    "print(f\"✓ Created guardrail: {GUARDRAIL_ID}\")\n",
    "print(f\"  Version: {GUARDRAIL_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Content Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_guardrail(prompt, guardrail_id, guardrail_version):\n",
    "    try:\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId='us.amazon.nova-lite-v1:0',\n",
    "            messages=[{'role': 'user', 'content': [{'text': prompt}]}],\n",
    "            guardrailConfig={\n",
    "                'guardrailIdentifier': guardrail_id,\n",
    "                'guardrailVersion': guardrail_version\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if response['stopReason'] == 'guardrail_intervened':\n",
    "            return {'blocked': True, 'reason': 'Guardrail intervention'}\n",
    "        \n",
    "        return {'blocked': False, 'response': response['output']['message']['content'][0]['text']}\n",
    "    except Exception as e:\n",
    "        return {'blocked': True, 'error': str(e)}\n",
    "\n",
    "# Test safe prompt\n",
    "result = test_with_guardrail(\"What is machine learning?\", GUARDRAIL_ID, GUARDRAIL_VERSION)\n",
    "print(f\"Safe prompt: {result}\\n\")\n",
    "\n",
    "# Test potentially harmful prompt\n",
    "result = test_with_guardrail(\"How to hack a computer?\", GUARDRAIL_ID, GUARDRAIL_VERSION)\n",
    "print(f\"Harmful prompt: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Guardrail with PII Redaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name='pii-redaction-guardrail',\n",
    "    description='Redact sensitive PII',\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': 'EMAIL', 'action': 'BLOCK'},\n",
    "            {'type': 'PHONE', 'action': 'BLOCK'},\n",
    "            {'type': 'NAME', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'ADDRESS', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'CREDIT_DEBIT_CARD_NUMBER', 'action': 'BLOCK'},\n",
    "            {'type': 'US_SOCIAL_SECURITY_NUMBER', 'action': 'BLOCK'}\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Input contains sensitive information.',\n",
    "    blockedOutputsMessaging='Output contains sensitive information.'\n",
    ")\n",
    "\n",
    "PII_GUARDRAIL_ID = response['guardrailId']\n",
    "PII_GUARDRAIL_VERSION = response['version']\n",
    "\n",
    "print(f\"✓ Created PII guardrail: {PII_GUARDRAIL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test PII Redaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with PII\n",
    "prompts_with_pii = [\n",
    "    \"My email is john.doe@example.com and phone is 555-1234\",\n",
    "    \"John Smith lives at 123 Main Street\",\n",
    "    \"My credit card is 4532-1234-5678-9010\"\n",
    "]\n",
    "\n",
    "for prompt in prompts_with_pii:\n",
    "    result = test_with_guardrail(prompt, PII_GUARDRAIL_ID, PII_GUARDRAIL_VERSION)\n",
    "    print(f\"Input: {prompt}\")\n",
    "    print(f\"Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Guardrail with Topic Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name='topic-blocking-guardrail',\n",
    "    description='Block specific topics',\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {\n",
    "                'name': 'Financial Advice',\n",
    "                'definition': 'Investment advice, stock tips, financial planning',\n",
    "                'examples': [\n",
    "                    'Should I invest in stocks?',\n",
    "                    'What stocks should I buy?',\n",
    "                    'Give me investment advice'\n",
    "                ],\n",
    "                'type': 'DENY'\n",
    "            },\n",
    "            {\n",
    "                'name': 'Medical Advice',\n",
    "                'definition': 'Medical diagnosis, treatment recommendations, health advice',\n",
    "                'examples': [\n",
    "                    'What medication should I take?',\n",
    "                    'How do I treat this condition?',\n",
    "                    'Diagnose my symptoms'\n",
    "                ],\n",
    "                'type': 'DENY'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='This topic is not allowed.',\n",
    "    blockedOutputsMessaging='Cannot provide information on this topic.'\n",
    ")\n",
    "\n",
    "TOPIC_GUARDRAIL_ID = response['guardrailId']\n",
    "TOPIC_GUARDRAIL_VERSION = response['version']\n",
    "\n",
    "print(f\"✓ Created topic guardrail: {TOPIC_GUARDRAIL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Topic Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"What is machine learning?\",  # Allowed\n",
    "    \"Should I invest in Bitcoin?\",  # Blocked - financial\n",
    "    \"What medication should I take for headache?\",  # Blocked - medical\n",
    "    \"Explain cloud computing\"  # Allowed\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    result = test_with_guardrail(prompt, TOPIC_GUARDRAIL_ID, TOPIC_GUARDRAIL_VERSION)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Guardrail with Word Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name='word-filter-guardrail',\n",
    "    description='Block specific words and phrases',\n",
    "    wordPolicyConfig={\n",
    "        'wordsConfig': [\n",
    "            {'text': 'competitor'},\n",
    "            {'text': 'confidential'},\n",
    "            {'text': 'internal only'}\n",
    "        ],\n",
    "        'managedWordListsConfig': [\n",
    "            {'type': 'PROFANITY'}\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Input contains blocked words.',\n",
    "    blockedOutputsMessaging='Output contains blocked words.'\n",
    ")\n",
    "\n",
    "WORD_GUARDRAIL_ID = response['guardrailId']\n",
    "WORD_GUARDRAIL_VERSION = response['version']\n",
    "\n",
    "print(f\"✓ Created word filter guardrail: {WORD_GUARDRAIL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Word Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"Tell me about AWS services\",  # Allowed\n",
    "    \"What about our competitor's product?\",  # Blocked\n",
    "    \"This is confidential information\",  # Blocked\n",
    "    \"Explain cloud architecture\"  # Allowed\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    result = test_with_guardrail(prompt, WORD_GUARDRAIL_ID, WORD_GUARDRAIL_VERSION)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Comprehensive Guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name='comprehensive-guardrail',\n",
    "    description='All protections enabled',\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {'type': 'HATE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'VIOLENCE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'SEXUAL', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'MISCONDUCT', 'inputStrength': 'MEDIUM', 'outputStrength': 'MEDIUM'}\n",
    "        ]\n",
    "    },\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': 'EMAIL', 'action': 'BLOCK'},\n",
    "            {'type': 'PHONE', 'action': 'BLOCK'},\n",
    "            {'type': 'NAME', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'CREDIT_DEBIT_CARD_NUMBER', 'action': 'BLOCK'}\n",
    "        ]\n",
    "    },\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {\n",
    "                'name': 'Financial Advice',\n",
    "                'definition': 'Investment and financial planning advice',\n",
    "                'examples': ['Should I invest?', 'Stock recommendations'],\n",
    "                'type': 'DENY'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    wordPolicyConfig={\n",
    "        'wordsConfig': [{'text': 'confidential'}],\n",
    "        'managedWordListsConfig': [{'type': 'PROFANITY'}]\n",
    "    },\n",
    "    blockedInputMessaging='Your input was blocked by our safety policies.',\n",
    "    blockedOutputsMessaging='The response was blocked by our safety policies.'\n",
    ")\n",
    "\n",
    "COMP_GUARDRAIL_ID = response['guardrailId']\n",
    "COMP_GUARDRAIL_VERSION = response['version']\n",
    "\n",
    "print(f\"✓ Created comprehensive guardrail: {COMP_GUARDRAIL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Use Guardrail with Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KB config if available\n",
    "try:\n",
    "    with open('kb_config.json', 'r') as f:\n",
    "        kb_config = json.load(f)\n",
    "    \n",
    "    KB_ID = kb_config['knowledge_base_id']\n",
    "    \n",
    "    bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=REGION)\n",
    "    \n",
    "    response = bedrock_agent_runtime.retrieve_and_generate(\n",
    "        input={'text': 'What equipment do we have?'},\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': KB_ID,\n",
    "                'modelArn': f'arn:aws:bedrock:{REGION}::foundation-model/amazon.nova-pro-v1:0',\n",
    "                'generationConfiguration': {\n",
    "                    'guardrailConfiguration': {\n",
    "                        'guardrailId': COMP_GUARDRAIL_ID,\n",
    "                        'guardrailVersion': COMP_GUARDRAIL_VERSION\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"✓ KB query with guardrail:\")\n",
    "    print(response['output']['text'])\n",
    "except FileNotFoundError:\n",
    "    print(\"KB config not found - run knowledge base notebook first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. List and Manage Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all guardrails\n",
    "response = bedrock.list_guardrails()\n",
    "\n",
    "print(\"Your Guardrails:\")\n",
    "for guardrail in response['guardrails']:\n",
    "    print(f\"  - {guardrail['name']} ({guardrail['id']}) v{guardrail['version']}\")\n",
    "\n",
    "# Get guardrail details\n",
    "response = bedrock.get_guardrail(\n",
    "    guardrailIdentifier=COMP_GUARDRAIL_ID,\n",
    "    guardrailVersion=COMP_GUARDRAIL_VERSION\n",
    ")\n",
    "\n",
    "print(f\"\\nComprehensive Guardrail Details:\")\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Guardrail Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_config = {\n",
    "    'content_filter': {'id': GUARDRAIL_ID, 'version': GUARDRAIL_VERSION},\n",
    "    'pii_redaction': {'id': PII_GUARDRAIL_ID, 'version': PII_GUARDRAIL_VERSION},\n",
    "    'topic_blocking': {'id': TOPIC_GUARDRAIL_ID, 'version': TOPIC_GUARDRAIL_VERSION},\n",
    "    'word_filter': {'id': WORD_GUARDRAIL_ID, 'version': WORD_GUARDRAIL_VERSION},\n",
    "    'comprehensive': {'id': COMP_GUARDRAIL_ID, 'version': COMP_GUARDRAIL_VERSION}\n",
    "}\n",
    "\n",
    "with open('guardrail_config.json', 'w') as f:\n",
    "    json.dump(guardrail_config, f, indent=2)\n",
    "\n",
    "print(\"✓ Guardrail config saved to guardrail_config.json\")\n",
    "print(json.dumps(guardrail_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete guardrails\n",
    "# for guardrail_id in [GUARDRAIL_ID, PII_GUARDRAIL_ID, TOPIC_GUARDRAIL_ID, WORD_GUARDRAIL_ID, COMP_GUARDRAIL_ID]:\n",
    "#     try:\n",
    "#         bedrock.delete_guardrail(guardrailIdentifier=guardrail_id)\n",
    "#         print(f\"✓ Deleted guardrail: {guardrail_id}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting {guardrail_id}: {e}\")\n",
    "\n",
    "print(\"Cleanup skipped - uncomment to delete guardrails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Guardrail Types:\n",
    "\n",
    "1. **Content Filters** - Block hate, violence, sexual, misconduct\n",
    "2. **PII Redaction** - Block/anonymize sensitive information\n",
    "3. **Topic Blocking** - Deny specific topics (financial, medical)\n",
    "4. **Word Filters** - Block specific words and profanity\n",
    "5. **Comprehensive** - All protections combined\n",
    "\n",
    "### Filter Strengths:\n",
    "\n",
    "- **NONE** - No filtering\n",
    "- **LOW** - Minimal filtering\n",
    "- **MEDIUM** - Moderate filtering\n",
    "- **HIGH** - Strict filtering\n",
    "\n",
    "### PII Actions:\n",
    "\n",
    "- **BLOCK** - Reject content with PII\n",
    "- **ANONYMIZE** - Replace PII with placeholders\n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "- **Customer Service** - Block harmful content, redact PII\n",
    "- **Healthcare** - Strict PII protection, medical topic control\n",
    "- **Financial** - Block financial advice, protect sensitive data\n",
    "- **Enterprise** - Prevent confidential information leakage\n",
    "\n",
    "### Integration:\n",
    "\n",
    "- Direct model invocation (Converse API)\n",
    "- Knowledge Base queries\n",
    "- Agent responses\n",
    "- Streaming responses\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. Start with comprehensive guardrail\n",
    "2. Test with real use cases\n",
    "3. Adjust filter strengths based on needs\n",
    "4. Monitor blocked content\n",
    "5. Update topic definitions regularly\n",
    "6. Use appropriate PII actions for your use case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
