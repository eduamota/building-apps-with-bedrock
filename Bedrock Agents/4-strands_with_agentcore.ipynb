{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands Agents with AgentCore Deployment\n",
    "Learn how to build agents with Strands framework and deploy them to AWS Bedrock AgentCore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required packages:\n",
    "```bash\n",
    "pip install strands-agents strands-agents-tools bedrock-agentcore bedrock-agentcore-starter-toolkit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strands-agents\n",
      "  Using cached strands_agents-1.19.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting strands-agents-tools\n",
      "  Using cached strands_agents_tools-0.2.17-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting bedrock-agentcore\n",
      "  Using cached bedrock_agentcore-1.1.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting bedrock-agentcore-starter-toolkit\n",
      "  Downloading bedrock_agentcore_starter_toolkit-0.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents) (1.42.4)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents) (1.42.4)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents) (4.25.1)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents)\n",
      "  Using cached mcp-1.23.1-py3-none-any.whl.metadata (88 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Using cached opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents)\n",
      "  Using cached opentelemetry_instrumentation_threading-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Using cached opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic<3.0.0,>=2.4.0 (from strands-agents)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents) (4.15.0)\n",
      "Collecting watchdog<7.0.0,>=6.0.0 (from strands-agents)\n",
      "  Using cached watchdog-6.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.6.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents) (0.30.0)\n",
      "Collecting anyio>=4.5 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached sse_starlette-3.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting starlette>=0.27 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting typing-inspection>=0.4.1 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting uvicorn>=0.31.1 (from mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents)\n",
      "  Using cached opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents)\n",
      "  Using cached wrapt-1.17.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-instrumentation==0.60b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents)\n",
      "  Using cached opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from opentelemetry-instrumentation==0.60b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents) (25.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.4.0->strands-agents)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.4.0->strands-agents)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents) (1.17.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.0 (from strands-agents-tools)\n",
      "  Using cached aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting aws-requests-auth<0.5.0,>=0.4.3 (from strands-agents-tools)\n",
      "  Using cached aws_requests_auth-0.4.3-py2.py3-none-any.whl.metadata (567 bytes)\n",
      "Collecting dill<0.5.0,>=0.4.0 (from strands-agents-tools)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting markdownify<2.0.0,>=1.0.0 (from strands-agents-tools)\n",
      "  Using cached markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pillow<12.0.0,>=11.2.1 (from strands-agents-tools)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents-tools) (3.0.52)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents-tools) (2.32.5)\n",
      "Collecting rich<15.0.0,>=14.0.0 (from strands-agents-tools)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting slack-bolt<2.0.0,>=1.23.0 (from strands-agents-tools)\n",
      "  Using cached slack_bolt-1.27.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy<2.0.0,>=1.12.0 (from strands-agents-tools)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from strands-agents-tools) (9.1.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting beautifulsoup4<5,>=4.9 (from markdownify<2.0.0,>=1.0.0->strands-agents-tools)\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools) (0.2.14)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools) (2025.11.12)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<15.0.0,>=14.0.0->strands-agents-tools)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools) (2.19.2)\n",
      "Collecting slack_sdk<4,>=3.38.0 (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools)\n",
      "  Using cached slack_sdk-3.39.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy<2.0.0,>=1.12.0->strands-agents-tools)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pre-commit>=4.2.0 (from bedrock-agentcore)\n",
      "  Using cached pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets>=12.0 (from bedrock-agentcore)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting autopep8>=2.3.2 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading autopep8-2.3.2-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from bedrock-agentcore-starter-toolkit) (3.1.6)\n",
      "Collecting openapi-spec-validator>=0.7.2 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting prance>=25.4.8.0 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting py-openapi-schema-to-json-schema>=0.0.3 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading py_openapi_schema_to_json_schema-0.0.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pyyaml>=6.0.2 (from bedrock-agentcore-starter-toolkit)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting questionary>=2.1.0 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ruamel-yaml>=0.18.14 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: toml>=0.10.2 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from bedrock-agentcore-starter-toolkit) (0.10.2)\n",
      "Collecting typer>=0.16.0 (from bedrock-agentcore-starter-toolkit)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pycodestyle>=2.12.0 (from autopep8>=2.3.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading pycodestyle-2.14.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from jinja2>=3.1.6->bedrock-agentcore-starter-toolkit) (3.0.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->strands-agents)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-spec-validator>=0.7.2->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting chardet>=5.2 (from prance>=25.4.8.0->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml>=0.18.14->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from typer>=0.16.0->bedrock-agentcore-starter-toolkit) (8.3.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.16.0->bedrock-agentcore-starter-toolkit)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/emota/miniconda3/envs/oreilly/lib/python3.13/site-packages (from virtualenv>=20.10.0->pre-commit>=4.2.0->bedrock-agentcore) (4.5.1)\n",
      "Using cached strands_agents-1.19.0-py3-none-any.whl (316 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached mcp-1.23.1-py3-none-any.whl (231 kB)\n",
      "Using cached opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
      "Using cached opentelemetry_instrumentation_threading-0.60b0-py3-none-any.whl (9.3 kB)\n",
      "Using cached opentelemetry_instrumentation-0.60b0-py3-none-any.whl (33 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
      "Using cached opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached watchdog-6.0.0-cp313-cp313-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached wrapt-1.17.3-cp313-cp313-macosx_11_0_arm64.whl (39 kB)\n",
      "Using cached strands_agents_tools-0.2.17-py3-none-any.whl (312 kB)\n",
      "Using cached aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl (489 kB)\n",
      "Using cached aws_requests_auth-0.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached slack_bolt-1.27.0-py2.py3-none-any.whl (230 kB)\n",
      "Using cached slack_sdk-3.39.0-py2.py3-none-any.whl (309 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached bedrock_agentcore-1.1.1-py3-none-any.whl (112 kB)\n",
      "Downloading bedrock_agentcore_starter_toolkit-0.2.2-py3-none-any.whl (462 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading autopep8-2.3.2-py2.py3-none-any.whl (45 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp313-cp313-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
      "Using cached cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
      "Using cached identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
      "Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading py_openapi_schema_to_json_schema-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "Downloading pycodestyle-2.14.0-py2.py3-none-any.whl (31 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl (181 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading questionary-2.1.1-py3-none-any.whl (36 kB)\n",
      "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-macosx_11_0_arm64.whl (133 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached sse_starlette-3.0.3-py3-none-any.whl (11 kB)\n",
      "Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Using cached virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
      "Using cached distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Installing collected packages: py-openapi-schema-to-json-schema, mpmath, distlib, wrapt, websockets, watchdog, typing-inspection, sympy, soupsieve, slack_sdk, shellingham, ruamel.yaml.clib, rfc3339-validator, referencing, pyyaml, python-multipart, python-dotenv, pyjwt, pydantic-core, pycparser, pycodestyle, propcache, pillow, pathable, nodeenv, multidict, mdurl, lazy-object-proxy, identify, httpx-sse, h11, frozenlist, filelock, docstring-parser, dill, chardet, cfgv, anyio, annotated-types, aiohappyeyeballs, yarl, virtualenv, uvicorn, starlette, sse-starlette, slack-bolt, ruamel-yaml, questionary, pydantic, opentelemetry-api, markdown-it-py, jsonschema-path, httpcore, cffi, beautifulsoup4, aws-requests-auth, autopep8, aiosignal, rich, pydantic-settings, pre-commit, prance, opentelemetry-semantic-conventions, markdownify, httpx, cryptography, aiohttp, typer, opentelemetry-sdk, opentelemetry-instrumentation, openapi-schema-validator, opentelemetry-instrumentation-threading, openapi-spec-validator, mcp, bedrock-agentcore, strands-agents, bedrock-agentcore-starter-toolkit, strands-agents-tools\n",
      "\u001b[2K  Attempting uninstall: referencing━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/78\u001b[0m [slack_sdk]\n",
      "\u001b[2K    Found existing installation: referencing 0.37.0━━━━━━━━━━━\u001b[0m \u001b[32m 9/78\u001b[0m [slack_sdk]\n",
      "\u001b[2K    Uninstalling referencing-0.37.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/78\u001b[0m [slack_sdk]\n",
      "\u001b[2K      Successfully uninstalled referencing-0.37.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/78\u001b[0m [slack_sdk]\n",
      "\u001b[2K  Attempting uninstall: pillowm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/78\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/78\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/78\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/78\u001b[0m [pydantic-core]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78/78\u001b[0m [strands-agents-tools]ts-tools]toolkit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.12.0 autopep8-2.3.2 aws-requests-auth-0.4.3 beautifulsoup4-4.14.3 bedrock-agentcore-1.1.1 bedrock-agentcore-starter-toolkit-0.2.2 cffi-2.0.0 cfgv-3.5.0 chardet-5.2.0 cryptography-46.0.3 dill-0.4.0 distlib-0.4.0 docstring-parser-0.17.0 filelock-3.20.0 frozenlist-1.8.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 identify-2.6.15 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 markdown-it-py-4.0.0 markdownify-1.2.2 mcp-1.23.1 mdurl-0.1.2 mpmath-1.3.0 multidict-6.7.0 nodeenv-1.9.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-api-1.39.0 opentelemetry-instrumentation-0.60b0 opentelemetry-instrumentation-threading-0.60b0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 pathable-0.4.4 pillow-11.3.0 prance-25.4.8.0 pre-commit-4.5.0 propcache-0.4.1 py-openapi-schema-to-json-schema-0.0.3 pycodestyle-2.14.0 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 pyjwt-2.10.1 python-dotenv-1.2.1 python-multipart-0.0.20 pyyaml-6.0.3 questionary-2.1.1 referencing-0.36.2 rfc3339-validator-0.1.4 rich-14.2.0 ruamel-yaml-0.18.16 ruamel.yaml.clib-0.2.15 shellingham-1.5.4 slack-bolt-1.27.0 slack_sdk-3.39.0 soupsieve-2.8 sse-starlette-3.0.3 starlette-0.50.0 strands-agents-1.19.0 strands-agents-tools-0.2.17 sympy-1.14.0 typer-0.20.0 typing-inspection-0.4.2 uvicorn-0.38.0 virtualenv-20.35.4 watchdog-6.0.0 websockets-15.0.1 wrapt-1.17.3 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents strands-agents-tools bedrock-agentcore bedrock-agentcore-starter-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import calculator\n",
    "from bedrock_agentcore import BedrockAgentCoreApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Strands Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll calculate 25 * 47 for you.\n",
      "Tool #1: calculator\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ╭───────────┬─────────────────────╮                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression </span>│                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 25 * 47             </span>│                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 1175                </span>│                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ╰───────────┴─────────────────────╯                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ╭───────────┬─────────────────────╮                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mEvaluate Expression\u001b[0m\u001b[32m \u001b[0m│                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m25 * 47            \u001b[0m\u001b[32m \u001b[0m│                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m1175               \u001b[0m\u001b[32m \u001b[0m│                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ╰───────────┴─────────────────────╯                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 * 47 = 117525 * 47 = 1175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple agent with calculator tool\n",
    "agent = Agent(tools=[calculator])\n",
    "response = agent(\"What is 25 * 47?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll get the current weather in Seattle and a 5-day forecast for you.\n",
      "Tool #1: get_weather\n",
      "\n",
      "Tool #2: get_forecast\n",
      "Here's the weather information for Seattle:\n",
      "\n",
      "**Current Weather:**\n",
      "- Temperature: 72°F\n",
      "- Condition: Sunny\n",
      "\n",
      "**5-Day Forecast:**\n",
      "Based on the available forecast data, here's what to expect:\n",
      "- Day 1: Sunny\n",
      "- Day 2: Cloudy  \n",
      "- Day 3: Rainy\n",
      "\n",
      "It looks like the forecast system returned data for 3 days instead of the full 5 days requested. The weather is currently pleasant and sunny at 72°F, but you can expect it to become cloudier and then rainy over the next few days - typical Seattle weather!Here's the weather information for Seattle:\n",
      "\n",
      "**Current Weather:**\n",
      "- Temperature: 72°F\n",
      "- Condition: Sunny\n",
      "\n",
      "**5-Day Forecast:**\n",
      "Based on the available forecast data, here's what to expect:\n",
      "- Day 1: Sunny\n",
      "- Day 2: Cloudy  \n",
      "- Day 3: Rainy\n",
      "\n",
      "It looks like the forecast system returned data for 3 days instead of the full 5 days requested. The weather is currently pleasant and sunny at 72°F, but you can expect it to become cloudier and then rainy over the next few days - typical Seattle weather!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get current weather for a city.\"\"\"\n",
    "    # Mock implementation\n",
    "    return {\"city\": city, \"temp\": 72, \"condition\": \"sunny\"}\n",
    "\n",
    "@tool\n",
    "def get_forecast(city: str, days: int = 3) -> dict:\n",
    "    \"\"\"Get weather forecast for a city.\"\"\"\n",
    "    return {\"city\": city, \"forecast\": [\"sunny\", \"cloudy\", \"rainy\"][:days]}\n",
    "\n",
    "weather_agent = Agent(\n",
    "    system_prompt=\"You are a weather assistant.\",\n",
    "    tools=[get_weather, get_forecast]\n",
    ")\n",
    "\n",
    "response = weather_agent(\"What's the weather in Seattle and give me a 5-day forecast?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jn/py_6v4j90519z5d9j8hh442r0000gn/T/ipykernel_70201/859571042.py:2: UserWarning: Invalid configuration parameters: ['region'].\n",
      "Valid parameters are: ['additional_args', 'additional_request_fields', 'additional_response_field_paths', 'cache_prompt', 'cache_tools', 'guardrail_id', 'guardrail_redact_input', 'guardrail_redact_input_message', 'guardrail_redact_output', 'guardrail_redact_output_message', 'guardrail_stream_processing_mode', 'guardrail_trace', 'guardrail_version', 'include_tool_result_status', 'max_tokens', 'model_id', 'stop_sequences', 'streaming', 'temperature', 'top_p'].\n",
      "\n",
      "See https://github.com/strands-agents/sdk-python/issues/815\n",
      "  nova_model = BedrockModel(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> To calculate the compound interest, I need to use the formula A = P(1 + r/n)^(nt), where:\n",
      "- A is the amount of money accumulated after n years, including interest.\n",
      "- P is the principal amount (the initial sum of money).\n",
      "- r is the annual interest rate (in decimal).\n",
      "- n is the number of times that interest is compounded per year.\n",
      "- t is the time the money is invested for in years.\n",
      "\n",
      "Since the problem does not specify how many times the interest is compounded per year, I will assume it is compounded annually (n = 1). The principal amount P is $10,000, the annual interest rate r is 5% (0.05 in decimal), and the time t is 3 years. I will use the 'evaluate' mode of the calculator tool to compute the final amount A. </thinking>\n",
      "\n",
      "\n",
      "Tool #1: calculator\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> ───────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ╭───────────┬───────────────────────────────╮                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression           </span>│                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 10000 * (1 + 0.05/1) ** (1*3) </span>│                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  │<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 11576.25                      </span>│                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ╰───────────┴───────────────────────────────╯                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ╭───────────┬───────────────────────────────╮                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mEvaluate Expression          \u001b[0m\u001b[32m \u001b[0m│                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m10000 * (1 + 0.05/1) ** (1*3)\u001b[0m\u001b[32m \u001b[0m│                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  │\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m11576.25                     \u001b[0m\u001b[32m \u001b[0m│                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ╰───────────┴───────────────────────────────╯                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The compound interest on $10,000 at 5% for 3 years, compounded annually, amounts to $11,576.25. \n",
      "\n",
      "To find the actual compound interest earned, subtract the principal amount from the final amount:\n",
      "$11,576.25 - $10,000 = $1,576.25\n",
      "\n",
      "So, the compound interest earned is $1,576.25.The compound interest on $10,000 at 5% for 3 years, compounded annually, amounts to $11,576.25. \n",
      "\n",
      "To find the actual compound interest earned, subtract the principal amount from the final amount:\n",
      "$11,576.25 - $10,000 = $1,576.25\n",
      "\n",
      "So, the compound interest earned is $1,576.25.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Amazon Bedrock Nova\n",
    "nova_model = BedrockModel(\n",
    "    model_id=\"us.amazon.nova-pro-v1:0\",\n",
    "    region=\"us-east-1\",\n",
    "    temperature=0.7,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "nova_agent = Agent(\n",
    "    model=nova_model,\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    tools=[calculator]\n",
    ")\n",
    "\n",
    "response = nova_agent(\"Calculate the compound interest on $10,000 at 5% for 3 years\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Pattern: Agents as Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you research AI trends and create a brief summary. Let me start by gathering current information on AI trends, then write a polished summary for you.\n",
      "Tool #1: research_assistant\n",
      "I'd be happy to help you with information about AI trends in 2024, but I don't have access to real-time data or current information through the available tools. The calculator tool I have access to is designed for mathematical operations rather than providing current research information.\n",
      "\n",
      "However, I can share some key AI trends that were emerging and continuing to develop around 2024 based on the trajectory of the field:\n",
      "\n",
      "**Major AI Trends in 2024:**\n",
      "\n",
      "1. **Large Language Models (LLMs) Evolution**\n",
      "   - More efficient and specialized models\n",
      "   - Reduced computational requirements\n",
      "   - Better reasoning capabilities\n",
      "\n",
      "2. **Generative AI Expansion**\n",
      "   - Beyond text to multimodal generation (text, image, video, audio)\n",
      "   - Integration into enterprise workflows\n",
      "   - Real-time generation capabilities\n",
      "\n",
      "3. **AI Regulation and Governance**\n",
      "   - Implementation of AI safety frameworks\n",
      "   - Regulatory compliance requirements\n",
      "   - Ethical AI development practices\n",
      "\n",
      "4. **Edge AI and Deployment**\n",
      "   - Running AI models on local devices\n",
      "   - Reduced latency and privacy improvements\n",
      "   - Mobile and IoT integration\n",
      "\n",
      "5. **AI Agent Systems**\n",
      "   - Autonomous task completion\n",
      "   - Multi-agent collaboration\n",
      "   - Integration with business processes\n",
      "\n",
      "6. **Specialized AI Applications**\n",
      "   - Healthcare diagnostics and drug discovery\n",
      "   - Climate modeling and sustainability\n",
      "   - Scientific research acceleration\n",
      "\n",
      "For the most current and detailed information about 2024 AI developments, I'd recommend checking recent publications from:\n",
      "- AI research institutions (OpenAI, DeepMind, Anthropic)\n",
      "- Industry reports from consulting firms\n",
      "- Academic conferences (NeurIPS, ICML, ICLR)\n",
      "- Technology news sources focused on AI\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of these trends?Now let me use the writing assistant to create a polished brief summary based on this research:\n",
      "Tool #2: writer_assistant\n",
      "# Key AI Trends Shaping 2024\n",
      "\n",
      "The artificial intelligence landscape in 2024 is characterized by six major trends that are transforming how we develop and deploy AI technologies:\n",
      "\n",
      "**1. Large Language Models Evolution**\n",
      "AI models are becoming more efficient and specialized, requiring less computational power while delivering enhanced reasoning capabilities. This evolution makes advanced AI more accessible and practical for widespread use.\n",
      "\n",
      "**2. Generative AI Expansion**\n",
      "Moving beyond text generation, AI now creates multimodal content including images, video, and audio. These capabilities are being integrated into enterprise workflows with real-time generation becoming standard.\n",
      "\n",
      "**3. AI Regulation and Governance**\n",
      "The industry is prioritizing safety through comprehensive frameworks, regulatory compliance measures, and ethical development practices, establishing responsible AI deployment standards.\n",
      "\n",
      "**4. Edge AI and Local Deployment**\n",
      "AI models are increasingly running on local devices rather than cloud servers, significantly reducing latency while improving privacy protection and enabling seamless mobile and IoT integration.\n",
      "\n",
      "**5. AI Agent Systems**\n",
      "Autonomous AI agents can now complete complex tasks independently, collaborate with other agents, and integrate directly into business processes, revolutionizing workflow automation.\n",
      "\n",
      "**6. Specialized AI Applications**\n",
      "AI is making significant advances in critical sectors including healthcare (diagnostics and drug discovery), environmental science (climate modeling and sustainability), and accelerating scientific research across disciplines.\n",
      "\n",
      "These trends collectively indicate AI's maturation from experimental technology to practical, regulated, and specialized tools that enhance both business operations and scientific advancement.I've researched current AI trends and created a comprehensive brief summary for you. The summary covers six major areas where AI is evolving in 2024:\n",
      "\n",
      "- **More efficient language models** with better reasoning\n",
      "- **Expanded generative AI** beyond text to multimedia content\n",
      "- **Increased regulation and governance** for responsible AI development\n",
      "- **Edge AI deployment** for better privacy and performance\n",
      "- **Autonomous AI agents** that can work independently and collaboratively\n",
      "- **Specialized applications** in healthcare, climate science, and research\n",
      "\n",
      "The summary highlights how AI is transitioning from experimental technology to practical, regulated tools that are being integrated into various industries and workflows. Would you like me to expand on any particular trend or adjust the summary in any way?I've researched current AI trends and created a comprehensive brief summary for you. The summary covers six major areas where AI is evolving in 2024:\n",
      "\n",
      "- **More efficient language models** with better reasoning\n",
      "- **Expanded generative AI** beyond text to multimedia content\n",
      "- **Increased regulation and governance** for responsible AI development\n",
      "- **Edge AI deployment** for better privacy and performance\n",
      "- **Autonomous AI agents** that can work independently and collaboratively\n",
      "- **Specialized applications** in healthcare, climate science, and research\n",
      "\n",
      "The summary highlights how AI is transitioning from experimental technology to practical, regulated tools that are being integrated into various industries and workflows. Would you like me to expand on any particular trend or adjust the summary in any way?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specialist agents as tools\n",
    "@tool\n",
    "def research_assistant(query: str) -> str:\n",
    "    \"\"\"Research specialist for gathering information.\"\"\"\n",
    "    research_agent = Agent(\n",
    "        system_prompt=\"You are a research specialist. Provide factual information.\",\n",
    "        tools=[calculator]\n",
    "    )\n",
    "    return str(research_agent(query))\n",
    "\n",
    "@tool\n",
    "def writer_assistant(content: str) -> str:\n",
    "    \"\"\"Writing specialist for creating polished content.\"\"\"\n",
    "    writer_agent = Agent(\n",
    "        system_prompt=\"You are a professional writer. Create clear, engaging content.\"\n",
    "    )\n",
    "    return str(writer_agent(f\"Write a summary: {content}\"))\n",
    "\n",
    "# Orchestrator agent\n",
    "orchestrator = Agent(\n",
    "    system_prompt=\"You coordinate between research and writing specialists.\",\n",
    "    tools=[research_assistant, writer_assistant]\n",
    ")\n",
    "\n",
    "response = orchestrator(\"Research AI trends and write a brief summary\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Agent Pattern: Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> The User has asked for an analysis of the benefits of cloud computing. While I can provide some information, a more detailed and comprehensive analysis would benefit from the expertise of the 'analyst' agent. Therefore, I will hand off this task to the analyst agent. </thinking>\n",
      "\n",
      "Tool #1: handoff_to_agent\n",
      "<thinking> I have successfully handed off the task to the 'analyst' agent. The analyst is now equipped with the necessary context to analyze the benefits of cloud computing. I will wait for the analyst's response. </thinking><thinking> The User has asked to analyze the benefits of cloud computing. I have previous knowledge that a researcher has already looked into this, but I don't have the specific findings. I should hand off the task to the researcher agent to get the detailed analysis. </thinking>\n",
      "\n",
      "<thinking> I will hand off the task to the researcher agent as they have already started working on this. I will include the previous context to ensure the researcher can pick up where they left off. </thinking>\n",
      "\n",
      "Tool #1: handoff_to_agent\n",
      "<thinking> The task has been successfully handed off to the researcher agent. I will now wait for the researcher to complete the analysis and provide a detailed report on the benefits of cloud computing. </thinking>Final: {'researcher': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"<thinking> I have successfully handed off the task to the 'analyst' agent. The analyst is now equipped with the necessary context to analyze the benefits of cloud computing. I will wait for the analyst's response. </thinking>\"}]}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={'handoff_to_agent': ToolMetrics(tool={'toolUseId': 'tooluse_wkRE4dGcTUWYyxAfS86oDg', 'name': 'handoff_to_agent', 'input': {'agent_name': 'analyst', 'context': {'UserRequest': 'Analyze the benefits of cloud computing'}, 'message': 'Please analyze the benefits of cloud computing.'}}, call_count=1, success_count=1, error_count=0, total_time=0.0003650188446044922)}, cycle_durations=[0.78078293800354], traces=[<strands.telemetry.metrics.Trace object at 0x132e69090>, <strands.telemetry.metrics.Trace object at 0x1344522b0>], accumulated_usage={'inputTokens': 3318, 'outputTokens': 155, 'totalTokens': 3473}, accumulated_metrics={'latencyMs': 1811}), state={}, interrupts=None, structured_output=None), execution_time=2176, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 3318, 'outputTokens': 155, 'totalTokens': 3473}, accumulated_metrics={'latencyMs': 1811}, execution_count=1), 'analyst': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': '<thinking> The task has been successfully handed off to the researcher agent. I will now wait for the researcher to complete the analysis and provide a detailed report on the benefits of cloud computing. </thinking>'}]}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={'handoff_to_agent': ToolMetrics(tool={'toolUseId': 'tooluse_Z8ge4syYSMaVMiGlAiTBNQ', 'name': 'handoff_to_agent', 'input': {'agent_name': 'researcher', 'context': {}, 'message': 'Please continue analyzing the benefits of cloud computing based on the previous research and provide a detailed report.'}}, call_count=1, success_count=1, error_count=0, total_time=0.00030303001403808594)}, cycle_durations=[0.7037317752838135], traces=[<strands.telemetry.metrics.Trace object at 0x134452350>, <strands.telemetry.metrics.Trace object at 0x134452f30>], accumulated_usage={'inputTokens': 1396, 'outputTokens': 195, 'totalTokens': 1591}, accumulated_metrics={'latencyMs': 2024}), state={}, interrupts=None, structured_output=None), execution_time=2382, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 1396, 'outputTokens': 195, 'totalTokens': 1591}, accumulated_metrics={'latencyMs': 2024}, execution_count=1)}\n",
      "Path: ['researcher', 'analyst']\n"
     ]
    }
   ],
   "source": [
    "from strands.multiagent import Swarm\n",
    "\n",
    "# Create specialized agents\n",
    "researcher = Agent(\n",
    "    name=\"researcher\",\n",
    "    system_prompt=\"Research and gather information, then hand off to analyst.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\"),\n",
    "    tools=[calculator]\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    name=\"analyst\",\n",
    "    system_prompt=\"Analyze data and hand off to writer.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\")\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    name=\"writer\",\n",
    "    system_prompt=\"Create final report based on analysis.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\")\n",
    ")\n",
    "\n",
    "# Configure swarm\n",
    "swarm = Swarm(\n",
    "    [researcher, analyst, writer],\n",
    "    max_handoffs=2,\n",
    "    max_iterations=3,\n",
    "    execution_timeout=300.0,\n",
    "    node_timeout=60.0\n",
    ")\n",
    "\n",
    "result = swarm(\"Analyze the benefits of cloud computing\")\n",
    "print(f\"Final: {result.results}\")\n",
    "print(f\"Path: {[node.node_id for node in result.node_history]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wrap Strands Agent for AgentCore Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll get the current weather information for Boston for you.\n",
      "Tool #1: get_weather\n",
      "The current weather in Boston is:\n",
      "- Temperature: 72°F\n",
      "- Condition: Sunny\n",
      "\n",
      "It's a beautiful day in Boston with pleasant temperatures and clear skies!{'result': \"The current weather in Boston is:\\n- Temperature: 72°F\\n- Condition: Sunny\\n\\nIt's a beautiful day in Boston with pleasant temperatures and clear skies!\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Create AgentCore app\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Create your Strands agent\n",
    "my_agent = Agent(\n",
    "    system_prompt=\"You are a helpful assistant with weather and calculation capabilities.\",\n",
    "    tools=[get_weather, get_forecast, calculator]\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    \"\"\"AgentCore entrypoint that wraps Strands agent.\"\"\"\n",
    "    prompt = payload.get(\"prompt\", \"Hello!\")\n",
    "    response = my_agent(prompt)\n",
    "    return {\"result\": str(response)}\n",
    "\n",
    "# Test locally\n",
    "if __name__ == \"__main__\":\n",
    "    # This would run the agent locally on port 8080\n",
    "    # app.run()\n",
    "    \n",
    "    # For notebook testing\n",
    "    test_payload = {\"prompt\": \"What's the weather in Boston?\"}\n",
    "    result = invoke(test_payload)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Agent for Deployment\n",
    "\n",
    "Save the agent code to a file for AgentCore deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent saved to strands_weather_agent.py\n"
     ]
    }
   ],
   "source": [
    "agent_code = '''\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator\n",
    "from bedrock_agentcore import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Get current weather for a city.\"\"\"\n",
    "    return {\"city\": city, \"temp\": 72, \"condition\": \"sunny\"}\n",
    "\n",
    "@tool\n",
    "def get_forecast(city: str, days: int = 3) -> dict:\n",
    "    \"\"\"Get weather forecast for a city.\"\"\"\n",
    "    return {\"city\": city, \"forecast\": [\"sunny\", \"cloudy\", \"rainy\"][:days]}\n",
    "\n",
    "agent = Agent(\n",
    "    system_prompt=\"You are a helpful weather and calculation assistant.\",\n",
    "    tools=[get_weather, get_forecast, calculator]\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    prompt = payload.get(\"prompt\", \"Hello!\")\n",
    "    response = agent(prompt)\n",
    "    return {\"result\": str(response)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "'''\n",
    "\n",
    "with open('strands_weather_agent.py', 'w') as f:\n",
    "    f.write(agent_code)\n",
    "\n",
    "print(\"✓ Agent saved to strands_weather_agent.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deploy to AgentCore\n",
    "\n",
    "Run these commands in terminal:\n",
    "\n",
    "```bash\n",
    "# Configure\n",
    "agentcore configure -e strands_weather_agent.py\n",
    "\n",
    "# Deploy\n",
    "agentcore deploy\n",
    "\n",
    "# Test\n",
    "agentcore invoke '{\"prompt\": \"What is the weather in Seattle?\"}'\n",
    "\n",
    "# Clean up\n",
    "agentcore destroy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!agentcore invoke '{\"prompt\": \"What is the weather in Seattle?\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!agentcore destroy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced: Multi-Agent Swarm for AgentCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_agent_code = '''\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.multiagent import Swarm\n",
    "from strands_tools import calculator\n",
    "from bedrock_agentcore import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Create swarm agents\n",
    "researcher = Agent(\n",
    "    name=\"researcher\",\n",
    "    system_prompt=\"Research and gather information.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\"),\n",
    "    tools=[calculator]\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    name=\"analyst\",\n",
    "    system_prompt=\"Analyze data and provide insights.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\")\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    name=\"writer\",\n",
    "    system_prompt=\"Create clear, concise reports.\",\n",
    "    model=BedrockModel(model_id=\"us.amazon.nova-lite-v1:0\")\n",
    ")\n",
    "\n",
    "swarm = Swarm(\n",
    "    agents=[researcher, analyst, writer],\n",
    "    max_handoffs=2,\n",
    "    max_iterations=2,\n",
    "    execution_timeout=180.0\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    prompt = payload.get(\"prompt\", \"Hello!\")\n",
    "    result = swarm(prompt)\n",
    "    return {\n",
    "        \"result\": str(result.final_response),\n",
    "        \"path\": [node.node_id for node in result.node_history]\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "'''\n",
    "\n",
    "with open('strands_swarm_agent.py', 'w') as f:\n",
    "    f.write(advanced_agent_code)\n",
    "\n",
    "print(\"✓ Swarm agent saved to strands_swarm_agent.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Invoke Deployed Agent Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "def invoke_agentcore_agent(agent_arn: str, prompt: str):\n",
    "    \"\"\"Invoke a deployed AgentCore agent.\"\"\"\n",
    "    client = boto3.client('bedrock-agentcore')\n",
    "    \n",
    "    payload = json.dumps({\"prompt\": prompt}).encode()\n",
    "    \n",
    "    response = client.invoke_agent_runtime(\n",
    "        agentRuntimeArn=agent_arn,\n",
    "        runtimeSessionId=str(uuid.uuid4()),\n",
    "        payload=payload,\n",
    "        qualifier=\"DEFAULT\"\n",
    "    )\n",
    "    \n",
    "    content = []\n",
    "    for chunk in response.get(\"response\", []):\n",
    "        content.append(chunk.decode('utf-8'))\n",
    "    \n",
    "    return json.loads(''.join(content))\n",
    "\n",
    "# Example usage (replace with your agent ARN)\n",
    "# agent_arn = \"arn:aws:bedrock-agentcore:us-east-1:123456789012:agent-runtime/my-agent\"\n",
    "# result = invoke_agentcore_agent(agent_arn, \"What's the weather in Boston?\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Strands Agent**: Lightweight, model-driven agent framework\n",
    "2. **Custom Tools**: Use `@tool` decorator to create agent capabilities\n",
    "3. **Multi-Agent Patterns**: Agents as Tools, Swarm, Graph, Workflow\n",
    "4. **AgentCore Integration**: Wrap Strands agents with `BedrockAgentCoreApp`\n",
    "5. **Deployment**: Use `agentcore` CLI for serverless deployment\n",
    "\n",
    "### Workflow\n",
    "\n",
    "```\n",
    "Build Strands Agent → Wrap with AgentCore → Deploy → Invoke\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- **Strands**: Simple, flexible, model-driven agent development\n",
    "- **AgentCore**: Production-ready serverless infrastructure\n",
    "- **Combined**: Best of both worlds - easy development + enterprise deployment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with different multi-agent patterns\n",
    "2. Add more sophisticated tools\n",
    "3. Deploy to AgentCore for production use\n",
    "4. Monitor with CloudWatch and AgentCore Observability\n",
    "5. Scale with AgentCore's serverless infrastructure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
